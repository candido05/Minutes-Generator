{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqfQonNEM-1F",
        "outputId": "38b03c52-dd59-41fc-acc1-482ee409258e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2024.12.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.59.9\n",
            "    Uninstalling openai-1.59.9:\n",
            "      Successfully uninstalled openai-1.59.9\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyC1KYkDNRh8",
        "outputId": "206f71d6-4f14-415d-da11-cb8df91f553b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Collecting noisereduce\n",
            "  Downloading noisereduce-3.0.3-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from noisereduce) (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from noisereduce) (4.67.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (4.55.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->noisereduce) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.12.14)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading noisereduce-3.0.3-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pydub, ffmpeg-python, noisereduce\n",
            "Successfully installed ffmpeg-python-0.2.0 noisereduce-3.0.3 pydub-0.25.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install ffmpeg-python pydub librosa noisereduce soundfile\n",
        "!apt-get install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O_cZSQygOpwj"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "from google.colab import userdata\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz8-l-bQOy5o"
      },
      "source": [
        "### Tratamento do audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "_ghe35ERO8SL",
        "outputId": "66ce2d71-eae3-4c3b-8e61-4b411dbb4348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Upload do arquivo ###\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cc7b8173-a008-47a8-a45e-10c2d9aafdff\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cc7b8173-a008-47a8-a45e-10c2d9aafdff\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving video_teste_medio.mp4 to video_teste_medio.mp4\n",
            "Arquivo recebido: video_teste_medio.mp4\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "def upload_file():\n",
        "    \"\"\"\n",
        "    Permite o upload de arquivos e salva localmente, verificando o tipo do arquivo.\n",
        "    \"\"\"\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        print(f\"Arquivo recebido: {filename}\")\n",
        "        file_ext = filename.split('.')[-1].lower()\n",
        "        if file_ext == \"mp4\":\n",
        "            return filename, 'video'\n",
        "        elif file_ext == \"mp3\":\n",
        "            return filename, 'mp3'\n",
        "        elif file_ext == \"wav\":\n",
        "            return filename, 'wav'\n",
        "        else:\n",
        "            print(\"Tipo de arquivo não suportado.\")\n",
        "            return None, None\n",
        "    return None, None\n",
        "\n",
        "print(\"### Upload do arquivo ###\")\n",
        "file_name, file_type = upload_file()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "d2EEyP7qpLam",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "20d38f69-c4a0-4695-c3d1-3645d125728c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-6-cabd4bb9f90f>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-cabd4bb9f90f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    print(\"Nenhum arquivo válido foi carregado.\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "if not file_name:0\n",
        "  print(\"Nenhum arquivo válido foi carregado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ANob5yAENCA"
      },
      "source": [
        "* Extração do Áudio e Verificação do Tamanho"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vlxUKzGSEMTj"
      },
      "outputs": [],
      "source": [
        "import ffmpeg\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def check_file_size(audio_path, max_size_mb=25):\n",
        "    \"\"\"\n",
        "    Verifica o tamanho do arquivo em MB.\n",
        "    \"\"\"\n",
        "    file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)  # Convertendo para MB\n",
        "    print(f\"Tamanho do arquivo: {file_size_mb:.2f} MB\")\n",
        "    return file_size_mb <= max_size_mb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BKybR3Cqgk0"
      },
      "source": [
        "Processamento video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qeefnY6LpdCU"
      },
      "outputs": [],
      "source": [
        "import ffmpeg\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def extract_and_split_audio_from_video(video_path, output_folder=\"audio_segments\", max_segment_size_mb=24):\n",
        "    \"\"\"\n",
        "    Extrai o áudio do vídeo e divide em segmentos menores que 24 MB.\n",
        "    \"\"\"\n",
        "    print(\"Extraindo áudio do vídeo...\")\n",
        "    audio_output_path = \"full_audio.wav\"\n",
        "    ffmpeg.input(video_path).output(audio_output_path, format='wav', acodec='pcm_s16le', ar='16000').run(quiet=True, overwrite_output=True)\n",
        "    print(f\"Áudio extraído: {audio_output_path}\")\n",
        "\n",
        "    # Verificar e dividir o áudio\n",
        "    return split_audio_into_segments(audio_output_path, output_folder, max_segment_size_mb)\n",
        "\n",
        "def split_audio_into_segments(audio_path, output_folder, max_segment_size_mb):\n",
        "    \"\"\"\n",
        "    Divide o áudio extraído em segmentos de até 24MB.\n",
        "    \"\"\"\n",
        "    print(f\"Dividindo áudio: {audio_path}\")\n",
        "    audio = AudioSegment.from_wav(audio_path)\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Calcular a duração do segmento baseado no tamanho máximo\n",
        "    bytes_per_second = len(audio.raw_data) / (len(audio) / 1000)\n",
        "    max_duration_ms = (max_segment_size_mb * 1024 * 1024) / bytes_per_second * 1000\n",
        "\n",
        "    segments = []\n",
        "    for i, start_ms in enumerate(range(0, len(audio), int(max_duration_ms))):\n",
        "        segment = audio[start_ms:start_ms + int(max_duration_ms)]\n",
        "        segment_path = os.path.join(output_folder, f\"segment_{i + 1}.wav\")\n",
        "        segment.export(segment_path, format=\"wav\")\n",
        "        segments.append(segment_path)\n",
        "        print(f\"Segmento criado: {segment_path} (Tamanho: {os.path.getsize(segment_path) / (1024 * 1024):.2f} MB)\")\n",
        "\n",
        "    return segments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRrxWE2jqjk8"
      },
      "source": [
        "Processamento mp3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sOrzcjJeql6b"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import noisereduce as nr\n",
        "import soundfile as sf\n",
        "\n",
        "def process_audio_mp3(mp3_path, output_dir):\n",
        "    \"\"\"\n",
        "    Processa o áudio MP3, reduzindo ruído e salvando o arquivo limpo.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    print(f\"Reduzindo ruído: {mp3_path}\")\n",
        "    audio_data, sr = librosa.load(mp3_path, sr=None)\n",
        "    reduced_noise = nr.reduce_noise(y=audio_data, sr=sr)\n",
        "\n",
        "    output_audio_path = os.path.join(output_dir, f\"cleaned_{os.path.basename(mp3_path)}\")\n",
        "    sf.write(output_audio_path, reduced_noise, sr)\n",
        "    print(f\"Áudio limpo salvo em: {output_audio_path}\")\n",
        "    return output_audio_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbBH2iRBqqRr"
      },
      "source": [
        "Processamento de WAV (Segmentação direta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Wdq2ASWLqso2"
      },
      "outputs": [],
      "source": [
        "def process_audio_wav(wav_path, output_folder):\n",
        "    \"\"\"\n",
        "    Processa o áudio WAV diretamente dividindo-o em segmentos menores de 24 MB.\n",
        "    \"\"\"\n",
        "    print(f\"Dividindo WAV diretamente: {wav_path}\")\n",
        "    return split_audio_into_segments(wav_path, output_folder, 24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyEQlQ0WEb4a",
        "outputId": "ff3b63a1-3f4c-4384-dfec-60c38cc793ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processando arquivo de vídeo...\n",
            "Extraindo áudio do vídeo...\n",
            "Áudio extraído: full_audio.wav\n",
            "Dividindo áudio: full_audio.wav\n",
            "Segmento criado: audio_segments/segment_1.wav (Tamanho: 24.00 MB)\n",
            "Segmento criado: audio_segments/segment_2.wav (Tamanho: 24.00 MB)\n",
            "Segmento criado: audio_segments/segment_3.wav (Tamanho: 24.00 MB)\n",
            "Segmento criado: audio_segments/segment_4.wav (Tamanho: 24.00 MB)\n",
            "Segmento criado: audio_segments/segment_5.wav (Tamanho: 24.00 MB)\n",
            "Segmento criado: audio_segments/segment_6.wav (Tamanho: 23.54 MB)\n",
            "Total de arquivos a serem processados: 6\n"
          ]
        }
      ],
      "source": [
        "if file_type == \"video\":\n",
        "    print(\"Processando arquivo de vídeo...\")\n",
        "    segments = extract_and_split_audio_from_video(file_name)\n",
        "elif file_type == \"mp3\":\n",
        "    print(\"Processando arquivo MP3...\")\n",
        "    output_dir = \"./cleaned_audio_mp3\"\n",
        "    cleaned_audio_path = process_audio_mp3(file_name, output_dir)\n",
        "    segments = [cleaned_audio_path]  # Como é um arquivo único, não precisa dividir\n",
        "elif file_type == \"wav\":\n",
        "    print(\"Processando arquivo WAV...\")\n",
        "    output_folder = \"./audio_segments_wav\"\n",
        "    segments = process_audio_wav(file_name, output_folder)\n",
        "\n",
        "print(f\"Total de arquivos a serem processados: {len(segments)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3-0FhR6PKrH"
      },
      "source": [
        " ### Redução de Ruído e Transcrição"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jq9IauZqPHhC"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import noisereduce as nr\n",
        "import soundfile as sf\n",
        "\n",
        "'''\n",
        "def process_audio(audio_path, output_audio_path):\n",
        "    \"\"\"\n",
        "    Reduz ruído no áudio e salva um novo arquivo.\n",
        "    \"\"\"\n",
        "    print(f\"Reduzindo ruído: {audio_path}\")\n",
        "    audio_data, sr = librosa.load(audio_path, sr=None)\n",
        "    reduced_noise = nr.reduce_noise(y=audio_data, sr=sr)\n",
        "    sf.write(output_audio_path, reduced_noise, sr)\n",
        "    return output_audio_path\n",
        "'''\n",
        "\n",
        "def process_audio(audio_path, output_dir):\n",
        "    \"\"\"\n",
        "    Reduz ruído no áudio e salva em um diretório específico.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    print(f\"Reduzindo ruído: {audio_path}\")\n",
        "    audio_data, sr = librosa.load(audio_path, sr=None)\n",
        "    reduced_noise = nr.reduce_noise(y=audio_data, sr=sr)\n",
        "\n",
        "    output_audio_path = os.path.join(output_dir, f\"cleaned_{os.path.basename(audio_path)}\")\n",
        "    sf.write(output_audio_path, reduced_noise, sr)\n",
        "    print(f\"Áudio limpo salvo em: {output_audio_path}\")\n",
        "    return output_audio_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "E-fGtbNMEk52"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def transcribe_audio(audio_path):\n",
        "    \"\"\"\n",
        "    Transcreve o áudio usando a API Whisper da OpenAI.\n",
        "    \"\"\"\n",
        "    print(f\"Transcrevendo: {audio_path}\")\n",
        "    with open(audio_path, \"rb\") as audio_file:\n",
        "        transcript = openai.Audio.transcribe(\"whisper-1\", audio_file, language=\"pt\")\n",
        "    return transcript['text']\n",
        "\n",
        "'''\n",
        "\n",
        "def transcribe_audio(audio_path):\n",
        "    \"\"\"\n",
        "    Transcreve o áudio usando a API Whisper da OpenAI.\n",
        "    \"\"\"\n",
        "    print(f\"Transcrevendo: {audio_path}\")\n",
        "    with open(audio_path, \"rb\") as audio_file:\n",
        "        transcript = openai.Audio.transcribe(\"whisper-1\", audio_file, language=\"pt\")\n",
        "    return transcript['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L6ny8w8Em2T",
        "outputId": "513cdb68-4a94-4af3-d4d8-c9e7d10a95bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processando segmento 1/6...\n",
            "Reduzindo ruído: audio_segments/segment_1.wav\n",
            "Áudio limpo salvo em: ./cleaned_audio/cleaned_segment_1.wav\n",
            "Transcrevendo: ./cleaned_audio/cleaned_segment_1.wav\n",
            "Processando segmento 2/6...\n",
            "Reduzindo ruído: audio_segments/segment_2.wav\n",
            "Áudio limpo salvo em: ./cleaned_audio/cleaned_segment_2.wav\n",
            "Transcrevendo: ./cleaned_audio/cleaned_segment_2.wav\n",
            "Processando segmento 3/6...\n",
            "Reduzindo ruído: audio_segments/segment_3.wav\n",
            "Áudio limpo salvo em: ./cleaned_audio/cleaned_segment_3.wav\n",
            "Transcrevendo: ./cleaned_audio/cleaned_segment_3.wav\n",
            "Processando segmento 4/6...\n",
            "Reduzindo ruído: audio_segments/segment_4.wav\n",
            "Áudio limpo salvo em: ./cleaned_audio/cleaned_segment_4.wav\n",
            "Transcrevendo: ./cleaned_audio/cleaned_segment_4.wav\n",
            "Processando segmento 5/6...\n",
            "Reduzindo ruído: audio_segments/segment_5.wav\n",
            "Áudio limpo salvo em: ./cleaned_audio/cleaned_segment_5.wav\n",
            "Transcrevendo: ./cleaned_audio/cleaned_segment_5.wav\n",
            "Processando segmento 6/6...\n",
            "Reduzindo ruído: audio_segments/segment_6.wav\n",
            "Áudio limpo salvo em: ./cleaned_audio/cleaned_segment_6.wav\n",
            "Transcrevendo: ./cleaned_audio/cleaned_segment_6.wav\n",
            "Transcrição concluída e salva em 'full_transcription.txt'.\n"
          ]
        }
      ],
      "source": [
        "cleaned_audio_dir = \"./cleaned_audio\"  # Pasta onde os áudios limpos serão salvos\n",
        "if not os.path.exists(cleaned_audio_dir):\n",
        "    os.makedirs(cleaned_audio_dir)\n",
        "\n",
        "full_transcription = \"\"\n",
        "for idx, segment_path in enumerate(segments):\n",
        "    print(f\"Processando segmento {idx+1}/{len(segments)}...\")\n",
        "    cleaned_audio_path = process_audio(segment_path, cleaned_audio_dir)\n",
        "    transcription = transcribe_audio(cleaned_audio_path)\n",
        "    full_transcription += transcription + \"\\n\"\n",
        "\n",
        "with open(\"full_transcription.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(full_transcription)\n",
        "\n",
        "print(\"Transcrição concluída e salva em 'full_transcription.txt'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "totm7sn7_cFK",
        "outputId": "c3e6d243-2392-49a8-9dd6-8727f0b303c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Processar e transcrever os segmentos\\nfull_transcription = \"\"\\nfor idx, segment_path in enumerate(segments):\\n    print(f\"Processando segmento {idx+1}/{len(segments)}...\")\\n    cleaned_audio = process_audio(segment_path, f\"cleaned_{os.path.basename(segment_path)}\")\\n    transcription = transcribe_audio(cleaned_audio)\\n    full_transcription += transcription + \"\\n\"\\n\\nwith open(\"full_transcription.txt\", \"w\", encoding=\"utf-8\") as f:\\n    f.write(full_transcription)\\n\\nprint(\"Transcrição concluída e salva em \\'full_transcription.txt\\'.\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "'''\n",
        "# Processar e transcrever os segmentos\n",
        "full_transcription = \"\"\n",
        "for idx, segment_path in enumerate(segments):\n",
        "    print(f\"Processando segmento {idx+1}/{len(segments)}...\")\n",
        "    cleaned_audio = process_audio(segment_path, f\"cleaned_{os.path.basename(segment_path)}\")\n",
        "    transcription = transcribe_audio(cleaned_audio)\n",
        "    full_transcription += transcription + \"\\n\"\n",
        "\n",
        "with open(\"full_transcription.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(full_transcription)\n",
        "\n",
        "print(\"Transcrição concluída e salva em 'full_transcription.txt'.\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SADSqTl1PU3s"
      },
      "source": [
        "### Geração das Atas da Reunião"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IPhgZyZSPatM"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def split_text_by_length(text, max_char_length=8000):\n",
        "    \"\"\"\n",
        "    Divide o texto em partes menores para garantir que cada parte não ultrapasse o limite da API.\n",
        "    :param text: Texto completo que precisa ser dividido.\n",
        "    :param max_char_length: Limite de caracteres para cada parte (aproximado para tokens).\n",
        "    :return: Lista com as partes do texto.\n",
        "    \"\"\"\n",
        "    print(\"Texto muito longo. Dividindo em partes...\")\n",
        "    parts = []\n",
        "    while len(text) > max_char_length:\n",
        "        split_index = text[:max_char_length].rfind('.')  # Encontrar o último ponto para dividir de forma natural\n",
        "        if split_index == -1:\n",
        "            split_index = max_char_length  # Divisão forçada se não encontrar ponto\n",
        "        parts.append(text[:split_index + 1])\n",
        "        text = text[split_index + 1:].strip()\n",
        "    parts.append(text)\n",
        "    print(f\"Texto dividido em {len(parts)} partes.\")\n",
        "    return parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2W_48A6uPZYE"
      },
      "outputs": [],
      "source": [
        "def summarize_text_as_minutes(text, part_number=1):\n",
        "    \"\"\"\n",
        "    Gera uma ata de reunião no formato especificado usando GPT-4.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Você é um assistente especializado em gerar atas de reuniões. A partir da transcrição a seguir, gere uma ata no formato:\n",
        "\n",
        "    1. Resumo Geral: Breve descrição do propósito e resultado da reunião.\n",
        "    2. Principais Tópicos: Liste os principais assuntos discutidos.\n",
        "    3. Ações e Responsáveis: Identifique ações importantes e quem são os responsáveis.\n",
        "    4. Métricas e Decisões: Liste números, decisões e acordos feitos.\n",
        "\n",
        "    A ata deve estar na norma culta da língua portuguesa e devidamente bem detalhada.\n",
        "\n",
        "    Transcrição (Parte {part_number}):\n",
        "    {text}\n",
        "    \"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Você é um assistente especialista em atas de reuniões.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.5\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "OYCdNkXZE-K6",
        "outputId": "82bb8d25-d5b7-49d5-e764-ae9efb9df564"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Gerar ata da reunião\\nprint(\"Gerando a ata da reunião...\")\\nfinal_summary = summarize_text_as_minutes(full_transcription)\\nprint(\"\\n### Ata Final da Reunião ###\")\\nprint(final_summary)\\n\\n# Salvar ata\\nwith open(\"meeting_minutes.txt\", \"w\", encoding=\"utf-8\") as f:\\n    f.write(final_summary)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "'''\n",
        "# Gerar ata da reunião\n",
        "print(\"Gerando a ata da reunião...\")\n",
        "final_summary = summarize_text_as_minutes(full_transcription)\n",
        "print(\"\\n### Ata Final da Reunião ###\")\n",
        "print(final_summary)\n",
        "\n",
        "# Salvar ata\n",
        "with open(\"meeting_minutes.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_summary)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djDZUMN5N15G",
        "outputId": "ddc96c9d-0d96-4d81-cf2a-fb4b01944877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verificando o tamanho da transcrição...\n",
            "Texto muito longo. Dividindo em partes...\n",
            "Texto dividido em 5 partes.\n",
            "Gerando a ata da Parte 1/5...\n",
            "Ata da Parte 1 concluída.\n",
            "\n",
            "Gerando a ata da Parte 2/5...\n",
            "Ata da Parte 2 concluída.\n",
            "\n",
            "Gerando a ata da Parte 3/5...\n",
            "Ata da Parte 3 concluída.\n",
            "\n",
            "Gerando a ata da Parte 4/5...\n",
            "Ata da Parte 4 concluída.\n",
            "\n",
            "Gerando a ata da Parte 5/5...\n",
            "Ata da Parte 5 concluída.\n",
            "\n",
            "Ata Parte 1 salva em './atas/ata_parte_1.txt'.\n",
            "Ata Parte 2 salva em './atas/ata_parte_2.txt'.\n",
            "Ata Parte 3 salva em './atas/ata_parte_3.txt'.\n",
            "Ata Parte 4 salva em './atas/ata_parte_4.txt'.\n",
            "Ata Parte 5 salva em './atas/ata_parte_5.txt'.\n",
            "\n",
            "### Atas Finais da Reunião ###\n",
            "\n",
            "### Ata Parte 1 ###\n",
            "\n",
            "1. Resumo Geral: \n",
            "A reunião, realizada em formato de podcast, discutiu principalmente os testes de pós-temporada do campeonato de MotoGP de 2024 e as previsões para a temporada de 2025. O encontro contou com a presença de Carlos Costa, Guilherme Longo e Fausto Maceira, comentarista do Mundial de Moto Velocidade na ESPN. \n",
            "\n",
            "2. Principais Tópicos: \n",
            "- Conclusão do campeonato de 2024 na MotoGP, com o título de Jorge Martins.\n",
            "- Transições de pilotos e equipes, incluindo Marques e Marques na Ducati Oficial de Fábrica e Martins mudando da Ducati para a Aprilha.\n",
            "- Testes preliminares e primeiros duelos entre Marques e Peco Banhaia na Ducati Oficial de Fábrica.\n",
            "- Expectativas e previsões para a temporada de 2025.\n",
            "- Avaliações dos testes realizados em Barcelona.\n",
            "- Desempenho de pilotos e equipes nos testes, incluindo Alex Marques, Fábio Quartararo, Peco Banhaia, e Jorge Martins.\n",
            "- Discussão sobre patrocínios e questões de marketing.\n",
            "\n",
            "3. Ações e Responsáveis: \n",
            "Não foram identificadas ações ou responsáveis específicos durante a reunião.\n",
            "\n",
            "4. Métricas e Decisões: \n",
            "- A temporada 2024 da MotoGP teve 40 corridas em 20 etapas.\n",
            "- Alex Marques foi o mais rápido nos testes, seguido por Fábio Quartararo e Peco Banhaia.\n",
            "- A Yamaha testou três motos diferentes para cada piloto.\n",
            "- A Honda optou por não levar muitas novidades para o teste, o que gerou críticas de alguns de seus pilotos.\n",
            "- A Ducati foi a equipe mais esperada nos testos, principalmente devido à estreia de Marques.\n",
            "- A Prilia teve a estreia de Martins, que ainda não decidiu se usará o número 89 ou 1 na próxima temporada.\n",
            "- A KTM teve destaque devido à queda de Bastianino durante os testes.\n",
            "- A Yamaha iniciou uma nova era com a Pramac, após o fim de uma longa parceria com a Ducati.\n",
            "\n",
            "### Ata Parte 2 ###\n",
            "\n",
            "1. Resumo Geral: A reunião foi uma discussão detalhada sobre as performances recentes e futuras de diversos pilotos e equipes de MotoGP. As discussões abrangeram desde performances individuais até questões mais amplas, como financiamento de equipe e desenvolvimento de motores.\n",
            "\n",
            "2. Principais Tópicos:\n",
            "   - Desempenho dos pilotos: Martim, Zarco, Alex Marques, Rins, Quartararo, Raul Fernandes, Zarco, Mir, Binder, Acosta, Vachellini, Miguel Oliveira, Miller, Sonqueat Champa, Altaguer, Bagnani, Marchi, Jorge Martini.\n",
            "   - Desempenho das equipes: Yamaha, Honda, Aprilha, KTM, Suzuki, Ducati.\n",
            "   - Discussão sobre o retorno potencial da Suzuki à MotoGP.\n",
            "   - Questões de financiamento e desenvolvimento de motores.\n",
            "\n",
            "3. Ações e Responsáveis:\n",
            "   - As equipes devem continuar desenvolvendo e melhorando suas motos e estratégias para a temporada 2025.\n",
            "   - A KTM precisa gerenciar seus recursos com sabedoria, já que a montadora negou a redução do investimento no programa da MotoGP.\n",
            "   - A Yamaha, Honda, Aprilha e KTM estão convidadas a desenvolver motos para 2027.\n",
            "   \n",
            "4. Métricas e Decisões:\n",
            "   - Quartararo ficou a 396 milésimos do Alex Marques, e Rins ficou no top 10, na oitava colocação. \n",
            "   - Zarco colocou a primeira ronda no top 10, à frente do Martin, que tomou o segundo do Alex Marques.\n",
            "   - Raul Fernandes foi o quinto mais rápido, com 1,25s.\n",
            "   - Bagnani e o Marchi ficaram separados por 5 centésimos de segundo em 3º e 4º lugares.\n",
            "   - A dupla Marques e Bagnani é vista como a mais forte do grid e será o foco da temporada.\n",
            "   - A Honda e a Suzuki podem retornar ao MotoGP, mas ainda não há uma decisão final.\n",
            "   - A Ducati não mostrou a sua nova carenagem, só vai mostrar no último teste.\n",
            "   - A Yamaha pode levar o motor V4 durante a temporada 2025.\n",
            "\n",
            "### Ata Parte 3 ###\n",
            "\n",
            "1. Resumo Geral: A reunião foi centrada na discussão sobre o desempenho dos pilotos e equipes em 2024 e as expectativas para 2025 na MotoGP. Os participantes expressaram suas opiniões sobre os pilotos Banhia, Marques, Martim, Acosta e outros, bem como as performances das equipes e as estratégias para a próxima temporada.\n",
            "\n",
            "2. Principais Tópicos:\n",
            "   - Avaliação do desempenho de Banhia e comparação com outros pilotos.\n",
            "   - Análise da situação da MotoGP em 2024 e previsões para 2025.\n",
            "   - Discussão sobre as equipes e suas estratégias.\n",
            "   - Avaliação dos testes de pré-temporada de Moto 2 e Moto 3.\n",
            "\n",
            "3. Ações e Responsáveis: Não foram identificadas ações específicas ou responsáveis durante a reunião.\n",
            "\n",
            "4. Métricas e Decisões:\n",
            "   - Foi mencionado que a Ducati tinha o favoritismo, mas que a KTM do Vinales foi a moto mais rápida nos testes.\n",
            "   - Foi mencionado que a Yamaha e a Honda têm muito a melhorar para a próxima temporada.\n",
            "   - Foi mencionado que a Aprilia precisaria dar um grande salto para estar na frente.\n",
            "   - Foi mencionado que o piloto Diogo Moreira ficou na segunda posição na Moto 2 nos testes de pré-temporada.\n",
            "   - Foi mencionado que Aron Canet foi o mais rápido na Moto 2 com um tempo de 1min47s88.\n",
            "   - Foi mencionado que o campeonato de 2024 foi decidido na 46ª corrida.\n",
            "   - Não foram tomadas decisões específicas durante a reunião.\n",
            "\n",
            "### Ata Parte 4 ###\n",
            "\n",
            "1. Resumo Geral: \n",
            "A reunião se concentrou na discussão dos recentes desenvolvimentos e performances em várias competições de motociclismo, incluindo a Moto2, Moto3, Supercross e outras. Os participantes discutiram os resultados dos competidores, analisaram suas performances e fizeram previsões para futuras competições. Além disso, também foi mencionado um evento da Red Bull no Rocos Ranch.\n",
            "\n",
            "2. Principais Tópicos:\n",
            "- Desempenho dos pilotos na Moto2 e Moto3, com destaque para Davi Alonso, Colin Weier, Tony Arbolino, Isa Guevara e Ivan Rostolá.\n",
            "- Desempenho de Dennis Ford e suas dificuldades em se adaptar à Moto3.\n",
            "- Participação de Diogo em um evento da Red Bull no Rocos Ranch e suas atividades de treinamento.\n",
            "- Discussão sobre o Mundial de Supercross na Austrália, com destaque para as vitórias de Light Tomek e Shane McElroy.\n",
            "- Desempenho de Enzo Lopes no Supercross e a possibilidade de se tornar vice-campeão mundial.\n",
            "\n",
            "3. Ações e Responsáveis:\n",
            "- Diogo: Participou de um evento da Red Bull e realizou atividades de treinamento.\n",
            "- Enzo Lopes: Competiu no Supercross e tem a possibilidade de se tornar vice-campeão mundial.\n",
            "\n",
            "4. Métricas e Decisões:\n",
            "- Davi Alonso melhorou seu tempo em 7 décimos no segundo dia de Moto2.\n",
            "- Enzo Lopes está em terceiro lugar no campeonato de Supercross, com possibilidade de se tornar vice-campeão mundial.\n",
            "- Light Tomek e Shane McElroy venceram as três etapas do Mundial de Supercross até agora.\n",
            "- A próxima etapa do Mundial de Supercross acontecerá em Abu Dhabi.\n",
            "- Eli Tomac lidera o campeonato SX com 47 pontos à frente de Ken Roxic.\n",
            "\n",
            "### Ata Parte 5 ###\n",
            "\n",
            "1. Resumo Geral: A reunião foi uma discussão sobre o mundo do motociclismo, com foco especial em corridas off-road e na areia. Os participantes discutiram os resultados recentes da Copa do Mundo de Corridas na Areia e falaram sobre os competidores notáveis, incluindo o campeão Todd Kellett e a campeã feminina Amandine Vestapen. Também mencionaram a presença do piloto português Paulo Alberto, que é conhecido no Brasil.\n",
            "\n",
            "2. Principais Tópicos:\n",
            "   - Discussão sobre a importância de ter um brasileiro como vice-campeão mundial.\n",
            "   - Análise da Copa do Mundo de Corridas na Areia, com foco na etapa de Monte Gordo em Portugal.\n",
            "   - Discussão sobre a performance de Todd Kellett e Amandine Vestapen.\n",
            "   - Menção à participação de Paulo Alberto em competições internacionais.\n",
            "   - Discussão sobre as dificuldades e particularidades de corridas na areia.\n",
            "   - Planejamento para futuras discussões sobre o mundo do motociclismo.\n",
            "\n",
            "3. Ações e Responsáveis:\n",
            "   - Todos os participantes: Continuar a acompanhar e discutir o mundo do motociclismo, com foco especial em competições off-road e na areia.\n",
            "   - Todos os participantes: Planejar uma confraternização do grupo no final do ano.\n",
            "\n",
            "4. Métricas e Decisões:\n",
            "   - Todd Kellett conquistou o segundo título consecutivo na Copa do Mundo de Corridas na Areia.\n",
            "   - Amandine Vestapen foi a campeã feminina, conquistando o título por antecipação.\n",
            "   - Paulo Alberto participou do Supercross de Paris e da Copa do Mundo de Corridas na Areia.\n",
            "   - A reunião terminou com o acordo de que todos continuarão a acompanhar e discutir as competições de motociclismo, com foco especial em corridas off-road e na areia.\n"
          ]
        }
      ],
      "source": [
        "atas_dir = \"./atas\"\n",
        "if not os.path.exists(atas_dir):\n",
        "    os.makedirs(atas_dir)\n",
        "\n",
        "# Simulação de uma transcrição muito longa\n",
        "print(\"Verificando o tamanho da transcrição...\")\n",
        "max_char_limit = 8000\n",
        "\n",
        "# Dividir a transcrição se necessário\n",
        "if len(full_transcription) > max_char_limit:\n",
        "    transcription_parts = split_text_by_length(full_transcription, max_char_limit)\n",
        "else:\n",
        "    transcription_parts = [full_transcription]\n",
        "\n",
        "final_summaries = []\n",
        "for i, part in enumerate(transcription_parts):\n",
        "    print(f\"Gerando a ata da Parte {i+1}/{len(transcription_parts)}...\")\n",
        "    summary = summarize_text_as_minutes(part, part_number=i+1)\n",
        "    final_summaries.append(summary)\n",
        "    print(f\"Ata da Parte {i+1} concluída.\\n\")\n",
        "\n",
        "# Salvar as atas na pasta 'atas'\n",
        "for i, summary in enumerate(final_summaries):\n",
        "    file_name = os.path.join(atas_dir, f\"ata_parte_{i+1}.txt\")\n",
        "    with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(summary)\n",
        "    print(f\"Ata Parte {i+1} salva em '{file_name}'.\")\n",
        "\n",
        "# Exibição das atas finais\n",
        "print(\"\\n### Atas Finais da Reunião ###\")\n",
        "for i, summary in enumerate(final_summaries):\n",
        "    print(f\"\\n### Ata Parte {i+1} ###\\n\")\n",
        "    print(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOpEPL6rCANV"
      },
      "source": [
        "### Agregando todas as atas e criando um reusmo geral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1VE9BaL4P4f8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import openai\n",
        "\n",
        "def read_meeting_parts_from_directory(directory, file_pattern=\"*.txt\"):\n",
        "    \"\"\"\n",
        "    Lê automaticamente todos os arquivos de texto de um diretório e retorna o conteúdo como uma lista.\n",
        "    :param directory: Caminho do diretório onde os arquivos estão localizados.\n",
        "    :param file_pattern: Padrão dos arquivos a serem lidos (default é *.txt).\n",
        "    :return: Lista com o conteúdo de cada arquivo.\n",
        "    \"\"\"\n",
        "    file_paths = glob.glob(os.path.join(directory, file_pattern))\n",
        "    meeting_parts = []\n",
        "\n",
        "    print(f\"Encontrados {len(file_paths)} arquivos no diretório '{directory}'.\")\n",
        "\n",
        "    for file_path in sorted(file_paths):\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            content = f.read()\n",
        "            meeting_parts.append(content)\n",
        "        print(f\"Arquivo '{file_path}' lido com sucesso.\")\n",
        "\n",
        "    return meeting_parts\n",
        "\n",
        "def combine_meeting_parts(meeting_parts):\n",
        "    \"\"\"\n",
        "    Une todas as partes da ata em uma ata final coesa.\n",
        "    \"\"\"\n",
        "    combined_text = \"\\n\".join(meeting_parts)\n",
        "    print(\"Todas as partes foram combinadas em uma única ata.\")\n",
        "    return combined_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mGGeIAaRP_vE"
      },
      "outputs": [],
      "source": [
        "def generate_full_summary(meeting_parts):\n",
        "    \"\"\"\n",
        "    Gera um resumo extenso e detalhado de todas as atas em um único parágrafo.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Abaixo estão várias atas de uma reunião. Gere um resumo total, extenso e detalhado, contendo o máximo de informações possíveis,\n",
        "    porém em um único parágrafo. O objetivo é criar um texto longo que resuma com precisão tudo que foi discutido.\n",
        "\n",
        "    Atas:\n",
        "    {meeting_parts}\n",
        "\n",
        "    Resumo Extenso e Detalhado:\n",
        "    \"\"\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Você é um assistente especialista em criar resumos extensos e detalhados de atas.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.5\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "uuxuCo01QC4K"
      },
      "outputs": [],
      "source": [
        "def generate_aggregated_minutes(meeting_parts):\n",
        "    \"\"\"\n",
        "    Agrega todas as atas em uma só ata com um formato estruturado.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Abaixo estão várias atas de uma reunião. Agrege todas em uma única ata, escolhendo as principais informações de cada uma.\n",
        "    Use a norma culta da língua portuguesa e siga o formato abaixo:\n",
        "\n",
        "    1. Resumo Geral: Breve descrição do propósito e resultado da reunião.\n",
        "    2. Principais Tópicos: Liste os principais assuntos discutidos.\n",
        "    3. Ações e Responsáveis: Identifique ações importantes e quem são os responsáveis.\n",
        "    4. Métricas e Decisões: Liste números, decisões e acordos feitos.\n",
        "\n",
        "    Atas:\n",
        "    {meeting_parts}\n",
        "\n",
        "    Ata Consolidada:\n",
        "    \"\"\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Você é um assistente especialista em criar atas consolidadas e detalhadas.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.5\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Zo1YwoIP0w2",
        "outputId": "e8f472bf-3764-4a7c-ea2f-db070d6a656f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lendo arquivos do diretório...\n",
            "Encontrados 5 arquivos no diretório './atas'.\n",
            "Arquivo './atas/ata_parte_1.txt' lido com sucesso.\n",
            "Arquivo './atas/ata_parte_2.txt' lido com sucesso.\n",
            "Arquivo './atas/ata_parte_3.txt' lido com sucesso.\n",
            "Arquivo './atas/ata_parte_4.txt' lido com sucesso.\n",
            "Arquivo './atas/ata_parte_5.txt' lido com sucesso.\n",
            "Consolidando a ata final...\n",
            "Todas as partes foram combinadas em uma única ata.\n",
            "Gerando resumo extenso e detalhado...\n",
            "Gerando ata consolidada...\n",
            "Ata final salva em 'ata_final_completa.txt'.\n",
            "Resumo extenso salvo em 'resumo_extenso.txt'.\n",
            "Ata consolidada salva em 'ata_consolidada.txt'.\n"
          ]
        }
      ],
      "source": [
        "directory_path = \"./atas\"\n",
        "\n",
        "print(\"Lendo arquivos do diretório...\")\n",
        "meeting_parts = read_meeting_parts_from_directory(directory_path)\n",
        "\n",
        "print(\"Consolidando a ata final...\")\n",
        "final_ata = combine_meeting_parts(meeting_parts)\n",
        "print(\"Gerando resumo extenso e detalhado...\")\n",
        "full_summary = generate_full_summary(\"\\n\".join(meeting_parts))\n",
        "print(\"Gerando ata consolidada...\")\n",
        "aggregated_minutes = generate_aggregated_minutes(\"\\n\".join(meeting_parts))\n",
        "\n",
        "with open(\"ata_final_completa.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_ata)\n",
        "print(\"Ata final salva em 'ata_final_completa.txt'.\")\n",
        "\n",
        "with open(\"resumo_extenso.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(full_summary)\n",
        "print(\"Resumo extenso salvo em 'resumo_extenso.txt'.\")\n",
        "\n",
        "with open(\"ata_consolidada.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(aggregated_minutes)\n",
        "print(\"Ata consolidada salva em 'ata_consolidada.txt'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g-_ub4GQZRP",
        "outputId": "2f927629-d5c8-4b9d-c869-f850f3248093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Resumo Extenso e Detalhado ###\n",
            "\n",
            "A reunião, realizada como um podcast, focou principalmente na avaliação do campeonato MotoGP de 2024 e nas previsões para a temporada de 2025. Os participantes, incluindo Carlos Costa, Guilherme Longo e Fausto Maceira, discutiram o título de Jorge Martins, as transições de pilotos e equipes, os testes preliminares e as expectativas para a próxima temporada. Avaliações dos testes realizados em Barcelona e o desempenho de pilotos como Alex Marques, Fábio Quartararo, Peco Banhaia e Jorge Martins foram discutidos, além de questões de patrocínio e marketing. \n",
            "\n",
            "Os participantes também discutiram o desempenho de pilotos como Martim, Zarco, Rins, Quartararo, Raul Fernandes, Zarco, Mir, Binder, Acosta, Vachellini, Miguel Oliveira, Miller, Sonqueat Champa, Altaguer, Bagnani, Marchi e Jorge Martini, bem como o desempenho das equipes Yamaha, Honda, Aprilia, KTM, Suzuki e Ducati. A possibilidade de retorno da Suzuki à MotoGP, questões de financiamento e desenvolvimento de motores também foram abordadas. \n",
            "\n",
            "A reunião também centrou-se na discussão sobre o desempenho dos pilotos e equipes em 2024 e as expectativas para 2025 na MotoGP, com foco em pilotos como Banhia, Marques, Martim, Acosta e outros, bem como as performances das equipes e as estratégias para a próxima temporada. O desempenho dos pilotos na Moto2 e Moto3, com destaque para Davi Alonso, Colin Weier, Tony Arbolino, Isa Guevara e Ivan Rostolá, o desempenho de Dennis Ford e suas dificuldades em se adaptar à Moto3 e a participação de Diogo em um evento da Red Bull no Rocos Ranch também foram discutidos. \n",
            "\n",
            "A reunião também abordou o mundo do motociclismo, com foco em corridas off-road e na areia, discutindo os resultados recentes da Copa do Mundo de Corridas na Areia e falando sobre competidores notáveis, incluindo o campeão Todd Kellett e a campeã feminina Amandine Vestapen. \n",
            "\n",
            "Ao longo da reunião, várias métricas foram discutidas, incluindo o fato de que a temporada 2024 da MotoGP teve 40 corridas em 20 etapas, Alex Marques foi o mais rápido nos testes, seguido por Fábio Quartararo e Peco Banhaia, a Yamaha testou três motos diferentes para cada piloto, a Honda optou por não levar muitas novidades para o teste, a Ducati foi a equipe mais esperada nos testos, principalmente devido à estreia de Marques, a Prilia teve a estreia de Martins, que ainda não decidiu se usará o número 89 ou 1 na próxima temporada, a KTM teve destaque devido à queda de Bastianino durante os testes, a Yamaha iniciou uma nova era com a Pramac, após o fim de uma longa parceria com a Ducati. \n",
            "\n",
            "A reunião terminou sem a identificação de ações ou responsáveis específicos, mas com o acordo de que todos os participantes continuarão a acompanhar e discutir as competições de motociclismo, com foco especial em corridas off-road e na areia.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n### Resumo Extenso e Detalhado ###\\n\")\n",
        "print(full_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBOsW7CxQb3N",
        "outputId": "06fd6976-8851-4951-dde8-db8c0f57d857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Ata Consolidada ###\n",
            "\n",
            "1. Resumo Geral: \n",
            "A reunião foi uma discussão abrangente sobre o mundo do motociclismo, cobrindo o desempenho dos pilotos e equipes em 2024 e as previsões para 2025 na MotoGP, assim como os resultados recentes de outras competições de motociclismo, incluindo a Moto2, Moto3, Supercross e a Copa do Mundo de Corridas na Areia. Os participantes expressaram suas opiniões sobre os pilotos, análises das performances das equipes e estratégias para a próxima temporada, além de discutir sobre os desafios e particularidades de corridas na areia.\n",
            "\n",
            "2. Principais Tópicos:\n",
            "- Avaliação do desempenho de pilotos na MotoGP, Moto2 e Moto3, incluindo Banhia, Marques, Martim, Acosta, Davi Alonso, Colin Weier, Tony Arbolino, Isa Guevara, Ivan Rostolá, e outros.\n",
            "- Análise do desempenho das equipes na MotoGP, incluindo Yamaha, Honda, Aprilha, KTM, Suzuki, Ducati, e suas respectivas estratégias.\n",
            "- Discussão sobre o retorno potencial da Suzuki à MotoGP.\n",
            "- Avaliação dos testes de pré-temporada de Moto 2 e Moto 3.\n",
            "- Discussão sobre o Mundial de Supercross na Austrália e o desempenho de Enzo Lopes.\n",
            "- Análise da Copa do Mundo de Corridas na Areia, com destaque para Todd Kellett e Amandine Vestapen.\n",
            "- Participação de Diogo em um evento da Red Bull no Rocos Ranch e suas atividades de treinamento.\n",
            "- Discussão sobre patrocínios, questões de marketing, e financiamento e desenvolvimento de motores.\n",
            "\n",
            "3. Ações e Responsáveis:\n",
            "- As equipes de MotoGP devem continuar desenvolvendo e melhorando suas motos e estratégias para a temporada 2025.\n",
            "- A KTM precisa gerenciar seus recursos com sabedoria, já que a montadora negou a redução do investimento no programa da MotoGP.\n",
            "- A Yamaha, Honda, Aprilha e KTM estão convidadas a desenvolver motos para 2027.\n",
            "- Diogo: Participou de um evento da Red Bull e realizou atividades de treinamento.\n",
            "- Enzo Lopes: Competiu no Supercross e tem a possibilidade de se tornar vice-campeão mundial.\n",
            "- Todos os participantes: Continuar a acompanhar e discutir o mundo do motociclismo, com foco especial em competições off-road e na areia.\n",
            "\n",
            "4. Métricas e Decisões:\n",
            "- Diversas métricas de desempenho dos pilotos e equipes foram discutidas, incluindo tempos de corrida, posições no campeonato e resultados de testes.\n",
            "- A Honda e a Suzuki podem retornar ao MotoGP, mas ainda não há uma decisão final.\n",
            "- A Yamaha pode levar o motor V4 durante a temporada 2025.\n",
            "- A Ducati não mostrou a sua nova carenagem, só vai mostrar no último teste.\n",
            "- Todd Kellett conquistou o segundo título consecutivo na Copa do Mundo de Corridas na Areia.\n",
            "- Amandine Vestapen foi a campeã feminina da Copa do Mundo de Corridas na Areia, conquistando o título por antecipação.\n",
            "- A reunião terminou com o acordo de que todos continuarão a acompanhar e discutir as competições de motociclismo, com foco especial em corridas off-road e na areia.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n### Ata Consolidada ###\\n\")\n",
        "print(aggregated_minutes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "W0gKUttKXjXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "429058f2-c86f-45a5-9c1d-3c028bf358cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "os: Biblioteca padrão do Python ou não instalada via pip\n",
            "openai: 0.28.0\n",
            "ffmpeg: Biblioteca padrão do Python ou não instalada via pip\n",
            "librosa: 0.10.2.post1\n",
            "noisereduce: 3.0.3\n",
            "soundfile: 0.13.0\n",
            "pydub: 0.25.1\n",
            "glob: Biblioteca padrão do Python ou não instalada via pip\n"
          ]
        }
      ],
      "source": [
        "import importlib.metadata\n",
        "\n",
        "# Lista das bibliotecas\n",
        "bibliotecas = [\n",
        "    \"os\",          # Biblioteca padrão do Python, não precisa de instalação\n",
        "    \"openai\",\n",
        "    \"ffmpeg\",\n",
        "    \"librosa\",\n",
        "    \"noisereduce\",\n",
        "    \"soundfile\",\n",
        "    \"pydub\",\n",
        "    \"glob\"         # Biblioteca padrão do Python, não precisa de instalação\n",
        "]\n",
        "\n",
        "# Verifica a versão de cada biblioteca\n",
        "for lib in bibliotecas:\n",
        "    try:\n",
        "        versao = importlib.metadata.version(lib)\n",
        "        print(f\"{lib}: {versao}\")\n",
        "    except importlib.metadata.PackageNotFoundError:\n",
        "        print(f\"{lib}: Biblioteca padrão do Python ou não instalada via pip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}